---
tags:
  - AI
  - prompt-engineering
  - LLM
created: 2026-02-13
---

# 为什么大模型总在"整理"时丢东西？

## 一个真实的踩坑经历

我最近用 AI 整理《金钱心理学》的读书笔记——把原文引用、人物故事和个人解读按章节重新组织。听起来很简单，结果来回改了五六轮：

- 第一轮：人物对比（里德 vs 福斯肯的详细背景）被压缩成一句话
- 第二轮：原文中的段落换行全部消失，变成一整块文字墙
- 第三轮：第2章中间的三段原文引用直接被吞掉
- 第四轮：我提供的"本章核心"总结行被删除

每一轮我都要逐段对比，找出被省略的内容，再要求补回来。用 Claude Code 如此，换 Codex 整理另一篇文章，同样的问题。

**这不是某个模型的 bug，而是所有大模型在"整理长文"任务中的系统性倾向。**

---

## 为什么会丢？五个底层原因

### 1. 模型天生有"压缩冲动"

大模型在训练阶段接触了海量的"摘要"和"精简"任务。当你说"整理这篇文章"，模型的默认理解更接近"精简+结构化"，而不是"保留所有内容+重新排版"。

这种倾向在底层权重里：**简洁通常意味着高评分**。模型会本能地砍掉它认为"冗余"的部分——重复的论述、过渡句、人物背景细节、并列的例子。但这些"冗余"对你来说可能恰恰是文章的血肉。

### 2. "整理"这个词太模糊

"整理"至少有五种理解：

| 你的意思 | 模型可能理解成 |
|---------|-------------|
| 重新排版，内容不动 | 精简提炼 |
| 补充结构，保留原文 | 改写润色 |
| 按模板重新组织 | 按模板裁剪内容 |
| 加解读，原文保留 | 用解读替代原文 |
| 分段+加标题 | 合并相似段落 |

你给的指令越模糊，模型的"自由裁量权"越大，丢内容的概率越高。

### 3. 长文本中间段落最容易丢失

这是注意力机制的结构性问题。模型在处理长文本时，**对开头和结尾的记忆最强，对中间部分最弱**——学术界称之为 "Lost in the Middle" 效应。

在我的实际经历中，序言和第1章的内容保留最完整，第2章中间的三段引用就被直接跳过了。这不是偶然。

### 4. 格式细节的优先级最低

模型会给内容做隐性的优先级排序：

```
核心论点 > 关键引用 > 故事情节 > 人物细节 > 段落换行 > 过渡句
```

当输出空间有限（或模型"觉得"应该更简洁）时，优先砍掉的就是排在后面的元素。这就是为什么**换行总是第一个消失**——模型不认为换行是"内容"，它觉得那只是"格式"。

### 5. 模板会加剧内容丢失

当你给模型一个结构化模板（比如"每段用 `> 引用` + `**解读**：` 的格式"），模型会把主要精力花在**填模板**上，而不是**保全原文**。

如果某段原文"不太好塞进模板"，模型会倾向于省略它，而不是调整模板。模板越严格，被省略的内容越多。

---

## 怎么提示才能少丢？

### 策略一：把"整理"替换成精确动词

不要说"整理这篇文章"，而是明确你要做的操作：

```markdown
# 模糊指令（容易丢内容）
请整理这篇读书笔记。

# 精确指令（保留完整）
请对这篇读书笔记做以下操作：
1. 按章节拆分为独立小节（## 标题）
2. 原文引用部分用 > 包裹，一字不删
3. 每段引用后补充 **解读**：段落
4. 段落之间保留原有的换行
```

关键词是：**一字不删、保留原文、不要省略、不要合并段落**。

### 策略二：用"负面约束"画红线

模型对"不要做什么"的响应往往比"要做什么"更敏感：

```markdown
注意事项：
- 不要省略任何原文段落
- 不要合并多个引用为一段
- 不要删除人物背景描写
- 不要移除段落之间的空行
- 如果某段原文不好归类，单独保留，不要丢弃
```

### 策略三：长文分批处理

一次性给5000字以上的原文，中间段落丢失概率显著升高。更好的做法：

```markdown
# 不推荐
这是全书20章的笔记，请按统一格式整理。

# 推荐
先整理第1-3章。以下是第1章的原文：[原文]
（完成后再给第4-6章）
```

每批控制在 2-3 章 / 2000-3000 字以内，让模型的注意力集中在当前内容上。

### 策略四：提供输入-输出对照样本

与其描述格式规则，不如直接给一个"输入→输出"的例子：

```markdown
# 示例——输入：
原文：巴菲特845亿美元的金融净资产中有815亿是在65岁以后赚到的。

# 示例——输出：
> 巴菲特845亿美元的金融净资产中有815亿是在65岁以后赚到的。

**解读**：这组数据几乎能打破所有对"投资天才"的误解……

# 现在请按上面的格式处理以下内容：
[你的原文]
```

模型看到具体样本后，"自由发挥"的空间会大幅缩小。

### 策略五：要求模型自查

整理完之后，追加一条指令：

```markdown
请对比原文，列出你在整理过程中省略、合并或改写的段落。
如果有遗漏，请补回。
```

模型有能力做这种自查——前提是你明确要求它做。它不会主动告诉你"我偷偷删了三段"。

### 策略六：分离"结构"和"内容"两步操作

不要让模型同时做"重新组织结构"和"填充内容"两件事。拆成两步：

```markdown
# 第一步：只做结构规划
请阅读以下原文，为每个段落设计一个 ## 小节标题，列出大纲。不要改动原文内容。

# 第二步：按大纲填充
按上面的大纲，把原文放入对应的小节中。原文保持原样，在每段后面添加解读。
```

两步分开做，模型在每一步的任务更单一，出错概率更低。

---

## 一张速查表

| 问题 | 原因 | 对策 |
|------|------|------|
| 原文被删减 | 压缩冲动 | 明确"一字不删" |
| 换行消失 | 格式优先级低 | 指定"保留段落换行" |
| 中间段落丢失 | 注意力衰减 | 分批处理，每批2-3章 |
| 人物细节被压缩 | 被判定为冗余 | "不要省略人物背景" |
| 多段引用被合并 | 追求简洁 | "每段引用独立保留" |
| 不好归类的内容消失 | 模板挤压 | "无法归类的内容单独保留" |

---

## 总结

大模型丢内容不是 bug，是**训练目标和用户意图之间的错位**。模型被优化为"生成简洁有用的回答"，而你想要的是"完整保留我的内容，只做结构调整"。

核心原则就一条：**你越精确地告诉模型"什么不能动"，它丢的就越少。**

不要假设模型理解"整理"的意思和你一样。每个模糊的词都是一个模型可能"自由发挥"的入口。把入口堵住，结果就会好得多。
